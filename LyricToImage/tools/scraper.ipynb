{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 지니, 벅스, 멜론에서 각각 음악 장르별 데이터 스크래핑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import logging\n",
    "import sys\n",
    "import time\n",
    "import re\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "from bs4 import BeautifulSoup as bs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(\"scraper.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(filename='logging_test.log', filemode='w', level=logging.INFO, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_time(func):\n",
    "    def wrapper():\n",
    "        start = time\n",
    "        start_time = time.time()\n",
    "        start_time_str = start.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        print(func.__name__)\n",
    "        logger.info(f\"start scrapping {func.__name__} function at {start_time_str}\")\n",
    "        \n",
    "        sleep_t = func()\n",
    "        \n",
    "        end = time\n",
    "        end_time = end.time()\n",
    "        end_time_str = end.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        end = time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        logger.info(f\"end scrapping {func.__name__} funtion at {end_time_str}\")\n",
    "        logger.info(f\"process_time : {end_time - start_time: .4f} s\")\n",
    "        logger.info(f\"process_time without sleep : {end_time - start_time - sleep_t: .4f} s\\n\")\n",
    "        \n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@process_time\n",
    "def scrap_melon():\n",
    "    category = {\"ballad\": \"0100\", \"dance\": \"0200\", \"rap&hiphop\": \"0300\", \"trot\": \"0700\", \"pop\": \"0900\", \"ost\": \"1500\"}\n",
    "    sleep_time = 0\n",
    "    for genre, code in zip(category.keys(), category.values()):\n",
    "        headers = {\"content-type\" : \"application/json;charset=UTF-8\", \"User-Agent\" : \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36 Edg/131.0.0.0\"}\n",
    "        res = requests.get(f\"https://www.melon.com/chart/day/index.htm?classCd=GN{code}\", headers=headers)\n",
    "        soup = bs(res.content, \"html.parser\")\n",
    "        with open(f'../assets/data/stage1/scrapper/melon/melon_scrap_{genre}_{time.strftime(\"%Y-%m-%d_%H%M%S\", time.localtime())}.html', 'w') as file:\n",
    "            file.write(soup.prettify())\n",
    "        \n",
    "        top50 = soup.find_all(\"tr\", id=\"lst50\")\n",
    "        top100 = top50 + soup.find_all(\"tr\", id=\"lst100\")\n",
    "        song_rank = []\n",
    "        \n",
    "        sleep = random.random() + 1\n",
    "        time.sleep(sleep)\n",
    "        sleep_time += sleep\n",
    "        \n",
    "        for song in top100:\n",
    "            song_rank.append(song.attrs['data-song-no'])\n",
    "        \n",
    "        for rank, songid in enumerate(song_rank):\n",
    "            res1 = requests.get(f\"https://www.melon.com/song/detail.htm?songId={songid}\", headers=headers)\n",
    "            soup1 = bs(res1.content, \"html.parser\")\n",
    "            with open(f'../assets/data/stage1/scrapper/melon/top100/{genre}/melon_scrap_{genre}_{rank + 1: 03d}_of_top100_{time.strftime(\"%Y-%m-%d_%H%M%S\", time.localtime())}.html', 'w') as file:\n",
    "                file.write(soup1.prettify())            \n",
    "            \n",
    "            sleep1 = random.random() + 1\n",
    "            time.sleep(sleep1)\n",
    "            \n",
    "            sleep_time += sleep1\n",
    "    \n",
    "    return sleep_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrap_genie():\n",
    "    category = {\"kpop\": \"0100\", \"trot\": \"0107\", \"pop\": \"0200\", \"ost\": \"0300\"}\n",
    "    sleep_time = 0\n",
    "    for genre, code in zip(category.keys(), category.values()):\n",
    "        headers = {\"content-type\" : \"application/json;charset=UTF-8\", \"User-Agent\" : \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36 Edg/131.0.0.0\"}\n",
    "        ymd = str(int(time.strftime(\"%Y%m%d\")) - 1)\n",
    "        \n",
    "        song_rank = []\n",
    "        for page in range(2): \n",
    "            \n",
    "            res = requests.get(f\"https://www.genie.co.kr/chart/genre?ditc=D&ymd={ymd}&genrecode=M{code}&pg={page+1}\", headers=headers)\n",
    "            soup = bs(res.content, \"html.parser\", from_encoding='utf-8')\n",
    "            \n",
    "            songid_list = soup.find_all(\"tr\", \"list\")\n",
    "            for song in songid_list:\n",
    "                song_rank.append(song.attrs['songid'])\n",
    "                \n",
    "                \n",
    "            with open(f'../assets/data/stage1/scrapper/genie/genie_scrap_{genre}_page{page+1}_{time.strftime(\"%Y-%m-%d_%H%M%S\", time.localtime())}.html', 'w', encoding='utf-8') as file:\n",
    "                file.write(soup.prettify())\n",
    "            \n",
    "            sleep = random.random() + 1\n",
    "            time.sleep(sleep)\n",
    "            sleep_time += sleep\n",
    "        print(song_rank)                    \n",
    "        for rank, songid in enumerate(song_rank):\n",
    "            res1 = requests.get(f\"https://www.genie.co.kr/detail/songInfo?xgnm={songid}\", headers=headers)\n",
    "            soup1 = bs(res1.content, \"html.parser\", from_encoding='utf-8')\n",
    "            with open(f'../assets/data/stage1/scrapper/genie/top100/{genre}/genie_scrap_{genre}_{rank + 1: 03d}_of_top100_{time.strftime(\"%Y-%m-%d_%H%M%S\", time.localtime())}.html', 'w', encoding='utf-8') as file:\n",
    "                file.write(soup1.prettify())            \n",
    "            \n",
    "            sleep1 = random.random() + 1\n",
    "            time.sleep(sleep1)\n",
    "            \n",
    "            sleep_time += sleep1\n",
    "    \n",
    "    return sleep_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@process_time\n",
    "def scrap_bugs():\n",
    "    category = {\"ballad\": \"nb\", \"dance\": \"ndp\", \"rap&hiphop\": \"nrh\", \"trot\": \"ntrot\", \"pop\": \"nfpop\", \"ost\": \"nost\"}\n",
    "    sleep_time = 0\n",
    "    for genre, code in zip(category.keys(), category.values()):\n",
    "        headers = {\"content-type\" : \"application/json;charset=UTF-8\", \"User-Agent\" : \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36 Edg/131.0.0.0\"}\n",
    "        ymd = str(int(time.strftime(\"%Y%m%d\")) - 1)\n",
    "        res = requests.get(f\"https://music.bugs.co.kr/chart/track/day/{code}?chartdate={ymd}\", headers=headers)\n",
    "        soup = bs(res.content, \"html.parser\")\n",
    "        with open(f'../assets/data/stage1/scrapper/bugs/bugs_scrap_{genre}_{time.strftime(\"%Y-%m-%d_%H%M%S\", time.localtime())}.html', 'w') as file:\n",
    "            file.write(soup.prettify())\n",
    "        \n",
    "        tbody = soup.find('tbody')\n",
    "        top100 = tbody.find_all('tr')\n",
    "        song_rank = []\n",
    "        \n",
    "        sleep = random.random() + 1\n",
    "        time.sleep(sleep)\n",
    "        sleep_time += sleep\n",
    "        \n",
    "        for song in top100:\n",
    "            song_rank.append(song.attrs['trackid'])\n",
    "        \n",
    "        for rank, songid in enumerate(song_rank):\n",
    "            res1 = requests.get(f\"https://music.bugs.co.kr/track/{songid}?wl_ref=list_tr_08_chart\", headers=headers)\n",
    "            soup1 = bs(res1.content, \"html.parser\")\n",
    "            with open(f'../assets/data/stage1/scrapper/bugs/top100/{genre}/bugs_scrap_{genre}_{rank + 1: 03d}_of_top100_{time.strftime(\"%Y-%m-%d_%H%M%S\", time.localtime())}.html', 'w') as file:\n",
    "                file.write(soup1.prettify())            \n",
    "            \n",
    "            sleep1 = random.random() + 1\n",
    "            time.sleep(sleep1)\n",
    "            \n",
    "            sleep_time += sleep1\n",
    "    \n",
    "    return sleep_time\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
